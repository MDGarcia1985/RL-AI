"""
maze_runner.py

Maze Runner Helper
Builds MazeEnv (walls/obstacles) and runs the shared training loop.

Design intent:
- Do NOT fork training logic.
- Keep one training loop (train_runner.run_training).
- Provide a convenient entry point for MazeEnv experiments.

Copyright (c) 2026 Michael Garcia, M&E Design
https://mandedesign.studio
michael@mandedesign.studio

CSC370 Spring 2026
"""
from __future__ import annotations

from typing import Sequence

from rc_agents.config.ui_config import TrainingUIConfig
from rc_agents.envs.maze_env import MazeConfig, MazeEnv, ascii_maze_to_walls
from rc_agents.edge_ai.rcg_edge.runners.train_runner import run_training


def run_maze_training_from_ascii(
    *,
    ascii_lines: Sequence[str],
    agent,
    cfg: TrainingUIConfig,
    start: tuple[int, int],
    goal: tuple[int, int],
    wall_chars: str = "#",
    step_cost: float = -1.0,
    goal_reward: float = 0.0,
    wall_penalty: float = -1.0,
):
    """
    Convenience helper:
    - Convert ASCII -> walls grid
    - Create MazeEnv
    - Call shared run_training()

    This keeps env swapping simple:
        GridEnv  -> run_training(...)
        MazeEnv  -> run_maze_training_from_ascii(...)
    """
    walls = ascii_maze_to_walls(ascii_lines, wall_chars=wall_chars)
    rows, cols = int(walls.shape[0]), int(walls.shape[1])

    env = MazeEnv(
        MazeConfig(
            rows=rows,
            cols=cols,
            start=start,
            goal=goal,
            step_cost=step_cost,
            goal_reward=goal_reward,
            wall_penalty=wall_penalty,
            walls=walls,
        )
    )

    return run_training(env=env, agent=agent, cfg=cfg)